# === Script 13 - G√©n√©ration du rapport final et upload dans MinIO ===
# Ce script synth√©tise tout le pipeline et archive le rapport dans MinIO.

import duckdb
import pandas as pd
import boto3
from botocore.exceptions import ClientError
from pathlib import Path
from loguru import logger
import sys
import warnings

warnings.filterwarnings("ignore")

# ----------------------------------------------------------------------
# Configuration logger
# ----------------------------------------------------------------------
logger.remove()
logger.add(sys.stdout, level="INFO", filter=lambda record: record["level"].name == "INFO")
logger.add(sys.stderr, level="WARNING")
LOGS_PATH = Path("logs")
LOGS_PATH.mkdir(parents=True, exist_ok=True)
logger.add(LOGS_PATH / "rapport_final.log", level="INFO", rotation="500 KB")

# ----------------------------------------------------------------------
# Connexion DuckDB
# ----------------------------------------------------------------------
try:
    con = duckdb.connect("data/bottleneck.duckdb")
    logger.success("‚úÖ Connexion √† DuckDB √©tablie.")
except Exception as e:
    logger.error(f"‚ùå Connexion √† DuckDB √©chou√©e : {e}")
    exit(1)

# ----------------------------------------------------------------------
# R√©cup√©ration des m√©triques pipeline
# ----------------------------------------------------------------------
try:
    logger.info("üìã R√©cup√©ration des informations du pipeline...")

    metrics = {}

    # Bruts
    metrics["ERP_brut"] = pd.read_csv("data/raw/erp.csv").shape[0]
    metrics["Web_brut"] = pd.read_csv("data/raw/web.csv").shape[0]
    metrics["Liaison_brut"] = pd.read_csv("data/raw/liaison.csv").shape[0]

    # Nettoy√©s
    metrics["ERP_nettoye"] = con.execute("SELECT COUNT(*) FROM erp_clean").fetchone()[0]
    metrics["Web_nettoye"] = con.execute("SELECT COUNT(*) FROM web_clean").fetchone()[0]
    metrics["Liaison_nettoye"] = con.execute("SELECT COUNT(*) FROM liaison_clean").fetchone()[0]

    # D√©doublonn√©s
    metrics["ERP_dedup"] = con.execute("SELECT COUNT(*) FROM erp_dedup").fetchone()[0]
    metrics["Web_dedup"] = con.execute("SELECT COUNT(*) FROM web_dedup").fetchone()[0]
    metrics["Liaison_dedup"] = con.execute("SELECT COUNT(*) FROM liaison_dedup").fetchone()[0]

    # Fusion
    metrics["Fusion"] = con.execute("SELECT COUNT(*) FROM fusion").fetchone()[0]

    # CA
    metrics["CA_total"] = con.execute("SELECT ca_total FROM ca_total").fetchone()[0]
    metrics["Produits_CA"] = con.execute("SELECT COUNT(*) FROM ca_par_produit").fetchone()[0]

    # Z-score
    metrics["Vins_millesimes"] = pd.read_csv("data/outputs/vins_millesimes.csv").shape[0]

    logger.success("‚úÖ Collecte des donn√©es r√©ussie.")

except Exception as e:
    logger.error(f"‚ùå Erreur r√©cup√©ration pipeline : {e}")
    exit(1)

# ----------------------------------------------------------------------
# Construction du DataFrame de rapport
# ----------------------------------------------------------------------
try:
    df_report = pd.DataFrame([
        {"√âtape": "Brut - ERP",         "R√©sultat": metrics["ERP_brut"],          "Attendu": ""},
        {"√âtape": "Brut - Web",         "R√©sultat": metrics["Web_brut"],          "Attendu": ""},
        {"√âtape": "Brut - Liaison",     "R√©sultat": metrics["Liaison_brut"],      "Attendu": ""},
        {"√âtape": "Nettoy√© - ERP",      "R√©sultat": metrics["ERP_nettoye"],       "Attendu": ""},
        {"√âtape": "Nettoy√© - Web",      "R√©sultat": metrics["Web_nettoye"],       "Attendu": ""},
        {"√âtape": "Nettoy√© - Liaison",  "R√©sultat": metrics["Liaison_nettoye"],   "Attendu": ""},
        {"√âtape": "D√©doublonn√© - ERP",  "R√©sultat": metrics["ERP_dedup"],         "Attendu": "825"},
        {"√âtape": "D√©doublonn√© - Web",  "R√©sultat": metrics["Web_dedup"],         "Attendu": "714"},
        {"√âtape": "D√©doublonn√© - Liaison", "R√©sultat": metrics["Liaison_dedup"],  "Attendu": "825"},
        {"√âtape": "Fusion finale",      "R√©sultat": metrics["Fusion"],            "Attendu": "714"},
        {"√âtape": "Produits CA",        "R√©sultat": metrics["Produits_CA"],       "Attendu": "573"},
        {"√âtape": "CA Total (‚Ç¨)",       "R√©sultat": round(metrics["CA_total"], 2),"Attendu": "387837.60"},
        {"√âtape": "Vins Mill√©sim√©s",    "R√©sultat": metrics["Vins_millesimes"],   "Attendu": "30"},
    ])

    OUTPUTS_PATH = Path("data/outputs")
    OUTPUTS_PATH.mkdir(parents=True, exist_ok=True)

    df_report.to_csv(OUTPUTS_PATH / "rapport_final.csv", index=False)
    df_report.to_excel(OUTPUTS_PATH / "rapport_final.xlsx", index=False)
    logger.success("üìÑ Rapport final export√© en CSV et XLSX.")

except Exception as e:
    logger.error(f"‚ùå Erreur export rapport : {e}")
    exit(1)

# ----------------------------------------------------------------------
# Upload du rapport dans MinIO
# ----------------------------------------------------------------------
MINIO_ENDPOINT = "http://host.docker.internal:9000"
ACCESS_KEY = "AKIAIOSFODNN7EXAMPLE"
SECRET_KEY = "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
BUCKET_NAME = "bottleneck"
DESTINATION_PREFIX = "data/outputs/"

try:
    s3_client = boto3.client(
        "s3",
        endpoint_url=MINIO_ENDPOINT,
        aws_access_key_id=ACCESS_KEY,
        aws_secret_access_key=SECRET_KEY,
        region_name="us-east-1",
    )

    for filename in ["rapport_final.csv", "rapport_final.xlsx"]:
        local_file = OUTPUTS_PATH / filename
        s3_key = f"{DESTINATION_PREFIX}{filename}"
        s3_client.upload_file(str(local_file), BUCKET_NAME, s3_key)
        logger.success(f"üöÄ Upload r√©ussi : {filename} vers {s3_key}")

except Exception as e:
    logger.error(f"‚ùå Erreur upload MinIO : {e}")
    exit(1)

logger.success("üéØ Rapport final complet archiv√© avec succ√®s dans MinIO.")
