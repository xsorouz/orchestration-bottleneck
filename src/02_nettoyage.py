# === Script 02 - Nettoyage enrichi sans filtre stock_status ===
# Ce script r√©alise une analyse initiale des CSV, applique un nettoyage m√©tier
# avec DuckDB en excluant le filtre sur `stock_status`, journalise chaque √©tape
# via loguru, et g√©n√®re un r√©sum√© des op√©rations.

import duckdb                        # DuckDB pour ex√©cution locale de SQL
import pandas as pd                  # Pandas pour l'analyse initiale des CSV
from pathlib import Path             # Gestion portable des chemins
from loguru import logger            # Logger riche en fonctionnalit√©s

import sys

logger.remove()
logger.add(sys.stdout, level="INFO", filter=lambda record: record["level"].name == "INFO")
logger.add(sys.stderr, level="WARNING")  # warnings, errors et criticals

# ------------------------------------------------------------------------------
# Configuration des logs
# - Cr√©e le dossier "logs" si n√©cessaire
# - Fichier de log "nettoyage.log" avec rotation tous les 500 KB
# ------------------------------------------------------------------------------
LOGS_PATH = Path("logs")
LOGS_PATH.mkdir(parents=True, exist_ok=True)
logger.add(LOGS_PATH / "nettoyage.log", level="INFO", rotation="500 KB")

# ------------------------------------------------------------------------------
# D√©finition des chemins d'entr√©e et de sortie
# - CSV_DIR : dossier source des CSV bruts
# - OUTPUT_DIR : dossier pour les exports apr√®s traitement
# ------------------------------------------------------------------------------
CSV_DIR = Path("data/raw")
OUTPUT_DIR = Path("data/outputs")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Fichiers CSV en entr√©e
erp_csv     = CSV_DIR / "erp.csv"
web_csv     = CSV_DIR / "web.csv"
liaison_csv = CSV_DIR / "liaison.csv"

logger.info("üìä Lecture des fichiers CSV pour analyse initiale...")

# ------------------------------------------------------------------------------
# Analyse initiale avec pandas : comptage des lignes et d√©tections sp√©cifiques
# ------------------------------------------------------------------------------
try:
    # Chargement des DataFrame
    df_erp     = pd.read_csv(erp_csv)
    df_web     = pd.read_csv(web_csv)
    df_liaison = pd.read_csv(liaison_csv)

    # Log des tailles initiales
    logger.info(f"ERP    : {len(df_erp)} lignes | WEB : {len(df_web)} | LIAISON : {len(df_liaison)}")

    # Comptage des lignes totalement vides dans chaque DataFrame
    logger.info(f"ERP    - lignes vides    : {df_erp.isnull().all(axis=1).sum()}")
    logger.info(f"WEB    - lignes vides    : {df_web.isnull().all(axis=1).sum()}")
    logger.info(f"LIAISON- lignes vides    : {df_liaison.isnull().all(axis=1).sum()}")

    # Analyse m√©tier WEB : lignes sans SKU mais autres champs renseign√©s
    df_web_sku_null = df_web[df_web["sku"].isnull()]
    ignored_cols = ["virtual", "downloadable", "rating_count"]
    cols_to_check = [col for col in df_web.columns if col not in ignored_cols + ["sku"]]
    df_web_partial = df_web_sku_null[df_web_sku_null[cols_to_check].notnull().any(axis=1)]

    logger.warning(f"WEB - {len(df_web_sku_null)} lignes avec sku NULL")
    logger.warning(f"WEB - {len(df_web_partial)} lignes avec sku NULL mais donn√©es partiellement pr√©sentes")

    # Exemples de lignes partielles (niveau debug)
    if len(df_web_partial) > 0:
        logger.debug("Exemple de ligne partielle :")
        logger.debug(df_web_partial[cols_to_check].head(2).to_string(index=False))

    # Analyse m√©tier ERP : exclusion des lignes o√π price ‚â§ 0
    df_erp_exclu = df_erp[df_erp["price"] <= 0]
    exclu_price = len(df_erp_exclu)
    logger.warning(f"ERP - {exclu_price} lignes exclues car price ‚â§ 0")

    # Analyse m√©tier LIAISON : exclusion des lignes id_web NULL
    df_liaison_exclu = df_liaison[df_liaison["id_web"].isnull()]
    logger.warning(f"LIAISON - {len(df_liaison_exclu)} lignes exclues car id_web NULL")

    # Export des lignes exclues pour audit
    df_erp_exclu.to_csv(OUTPUT_DIR / "erp_exclu.csv", index=False)
    df_liaison_exclu.to_csv(OUTPUT_DIR / "liaison_exclu.csv", index=False)
    logger.info("üìÅ Lignes exclues export√©es dans data/outputs")

except Exception as e:
    # Log de l'erreur et sortie en cas de probl√®me d'analyse
    logger.error(f"‚ùå Erreur pendant l'analyse initiale : {e}")
    exit(1)

# ------------------------------------------------------------------------------
# Connexion √† DuckDB et nettoyage m√©tier (sans filtre `stock_status`)
# ------------------------------------------------------------------------------
try:
    con = duckdb.connect("data.duckdb")
    logger.info("ü¶Ü Connexion √† DuckDB √©tablie.")
except Exception as e:
    logger.error(f"‚ùå Connexion √† DuckDB √©chou√©e : {e}")
    exit(1)

try:
    # Nettoyage ERP : filtre sur product_id, onsale_web, price > 0, stock_quantity pr√©sent
    con.execute("""
        CREATE OR REPLACE TABLE erp_clean AS
        SELECT * FROM read_csv_auto('data/raw/erp.csv')
        WHERE product_id IS NOT NULL
          AND onsale_web IS NOT NULL
          AND price IS NOT NULL AND price > 0
          AND stock_quantity IS NOT NULL
          AND stock_status IS NOT NULL
    """)
    logger.success("‚úÖ Table erp_clean cr√©√©e sans filtre stock_status.")

    # Nettoyage WEB : conserve les lignes avec SKU non nul
    con.execute("""
        CREATE OR REPLACE TABLE web_clean AS
        SELECT * FROM read_csv_auto('data/raw/web.csv')
        WHERE sku IS NOT NULL
    """)
    logger.success("‚úÖ Table web_clean cr√©√©e.")

    # Nettoyage LIAISON : conserve les associations product_id/id_web valides
    con.execute("""
        CREATE OR REPLACE TABLE liaison_clean AS
        SELECT * FROM read_csv_auto('data/raw/liaison.csv')
        WHERE product_id IS NOT NULL
          AND id_web IS NOT NULL
    """)
    logger.success("‚úÖ Table liaison_clean cr√©√©e.")

except Exception as e:
    # Erreur durant le nettoyage SQL
    logger.error(f"‚ùå Erreur lors du nettoyage dans DuckDB : {e}")
    exit(1)

# ------------------------------------------------------------------------------
# Validation post-nettoyage et g√©n√©ration d'un r√©sum√©
# ------------------------------------------------------------------------------
try:
    # Comptage des lignes dans chaque table nettoy√©e
    nb_erp     = con.execute("SELECT COUNT(*) FROM erp_clean").fetchone()[0]
    nb_web     = con.execute("SELECT COUNT(*) FROM web_clean").fetchone()[0]
    nb_liaison = con.execute("SELECT COUNT(*) FROM liaison_clean").fetchone()[0]

    # Assertions pour s'assurer que les tables ne sont pas vides
    assert nb_erp     > 0, "ERP nettoy√© vide"
    assert nb_web     > 0, "Web nettoy√© vide"
    assert nb_liaison > 0, "Liaison nettoy√© vide"

    logger.info(f"‚úîÔ∏è  Lignes apr√®s nettoyage - ERP: {nb_erp}, Web: {nb_web}, Liaison: {nb_liaison}")

    # Construction du DataFrame de r√©sum√©
    resume_df = pd.DataFrame({
        "source": ["erp", "web", "liaison"],
        "nb_lignes_initiales": [len(df_erp), len(df_web), len(df_liaison)],
        "nb_apres_nettoyage"  : [nb_erp, nb_web, nb_liaison],
        "nb_exclues"          : [exclu_price, len(df_web[df_web["sku"].isnull()]), len(df_liaison_exclu)]
    })

    # Export du r√©sum√© sous forme de CSV
    resume_df.to_csv(OUTPUT_DIR / "resume_stats.csv", index=False)
    logger.success("üìà Fichier de r√©sum√© export√© : resume_stats.csv")
    logger.success("üéâ Nettoyage termin√© avec succ√®s.")

except Exception as e:
    # Erreur dans la validation ou l'export du r√©sum√©
    logger.error(f"‚ùå Erreur dans les validations post-nettoyage : {e}")
    exit(1)
